# LLM Lab

## Prerequisites

- [ ] [Mise](https://mise.jdx.dev)
- [ ] Docker
- [ ] Recent graphics drivers + CUDA support

## Running locally

```shell
# Install prerequisites
mise install

# Enter Poetry shell
poetry shell

# Start the Ollama backend
task

# Run the chatbot
python -m llm_lab
```
